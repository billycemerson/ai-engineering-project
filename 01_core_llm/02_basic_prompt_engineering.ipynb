{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjPFQsyzcjpeEOdpgACerR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/billycemerson/ai-engineering-project/blob/main/01_core_llm/02_basic_prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt engineering is the art and science of designing and optimizing prompts to guide AI models, particularly LLMs, towards generating the desired responses."
      ],
      "metadata": {
        "id": "pm3JNcnSkRV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will hands on same basic example of prompt engineeering."
      ],
      "metadata": {
        "id": "prw4l7P7keHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, prompt engineering have some componenet:\n",
        "\n",
        "- Instruction → what should the  model do\n",
        "\n",
        "- Context → additional information\n",
        "\n",
        "- Input → data to process\n",
        "\n",
        "- Output format → model answer"
      ],
      "metadata": {
        "id": "pf_v2BrWkr_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Package & Library"
      ],
      "metadata": {
        "id": "gb2-oExSj0Sw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "MCzOtd4Vdt03"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "S-gl1E1jj6e4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuration"
      ],
      "metadata": {
        "id": "i6OFFGAWkAiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API KEY from input\n",
        "import getpass\n",
        "\n",
        "api_key = getpass.getpass(\"Enter your API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7zEZk-WkDGQ",
        "outputId": "7208064d-d0d7-4991-95d3-445042d5fea0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "MaiPapvEmf0k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Model"
      ],
      "metadata": {
        "id": "VpVtlXtMmGkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "Dn4ID4JRmF74"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prompt Technique"
      ],
      "metadata": {
        "id": "eAzU7E7Vmop_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some prompt engineering technique. In this example we will explore some fo them"
      ],
      "metadata": {
        "id": "MnIK9Y7-mrkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Zero-shot Prompting"
      ],
      "metadata": {
        "id": "iYQWQZzgm2Y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt without example. Good for simple task"
      ],
      "metadata": {
        "id": "gkJad37pm61A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Klasifikasikan sentimen teks berikut: 'Produk ini sangat mengecewakan'\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qDP-t-WvkHTj",
        "outputId": "5faaf9b4-930a-4f43-db4f-1c3fd507ef4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimen dari teks \"Produk ini sangat mengecewakan\" adalah **Negatif**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### One-shot Prompting"
      ],
      "metadata": {
        "id": "xKLyxdZEoAJz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt with one example to redirect the output."
      ],
      "metadata": {
        "id": "DSPv-h3LoD4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Contoh:\n",
        "Teks: Produk ini bagus sekali\n",
        "Sentimen: Positive\n",
        "\n",
        "Sekarang klasifikasikan:\n",
        "Teks: Pengiriman lama dan kualitas buruk\n",
        "Sentimen:\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "yVl3SQTroKtY",
        "outputId": "513ad43f-6437-414a-a722-b7d717185167"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks: Pengiriman lama dan kualitas buruk\n",
            "Sentimen: **Negative**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Role Prompting"
      ],
      "metadata": {
        "id": "OfBEZHJPoUUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign explicit roles to models."
      ],
      "metadata": {
        "id": "KDfupEgDoWlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are an expert Indonesian sentiment analyst.\n",
        "Tentukan sentimen dari teks berikut:\n",
        "\n",
        "\"Pelayanannya ramah dan cepat\"\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "bl5zfIi8oVrG",
        "outputId": "609d9d23-ab8c-4e39-a0ae-fb4d98962584"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentimen: **Positif**\n",
            "\n",
            "**Alasan:** Kedua kata sifat \"ramah\" dan \"cepat\" memiliki konotasi yang sangat positif dalam konteks pelayanan. \"Ramah\" menunjukkan sikap yang menyenangkan dan bersahabat, sementara \"cepat\" menunjukkan efisiensi dan responsivitas. Keduanya merupakan atribut yang diinginkan dan dihargai dalam pengalaman pelayanan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Output Control"
      ],
      "metadata": {
        "id": "pvP2hto5ojVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Control the output format to be consistent (JSON)."
      ],
      "metadata": {
        "id": "Qnj4CzlAopVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Klasifikasikan sentimen teks berikut.\n",
        "Output HARUS dalam format JSON.\n",
        "\n",
        "Teks: \"Harga mahal tapi kualitas bagus\"\n",
        "\n",
        "Format:\n",
        "{\n",
        "  \"sentiment\": \"<positive|negative>\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "8vMS6cAsolTA",
        "outputId": "d63a4a97-e078-402d-c932-ab37df7f8744"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"sentiment\": \"positive\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Task Decomposition"
      ],
      "metadata": {
        "id": "9zS0IPz_ozEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Break down complex tasks into small steps."
      ],
      "metadata": {
        "id": "rtR5C7SAo4FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Analisis teks berikut dengan langkah:\n",
        "1. Identifikasi kata kunci\n",
        "2. Tentukan sentimen\n",
        "3. Berikan kesimpulan singkat\n",
        "\n",
        "Teks: \"Aplikasi sering crash dan tidak responsif\"\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "pFaPj6IMo0YW",
        "outputId": "3ad3076d-d445-4237-d423-331bc81a952d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Berikut analisis teks \"Aplikasi sering crash dan tidak responsif\":\n",
            "\n",
            "1.  **Identifikasi Kata Kunci**\n",
            "    *   Aplikasi\n",
            "    *   sering crash\n",
            "    *   tidak responsif\n",
            "\n",
            "2.  **Tentukan Sentimen**\n",
            "    *   **Negatif kuat.** Kata \"crash\" dan \"tidak responsif\" secara jelas menunjukkan masalah kinerja yang serius dan pengalaman pengguna yang buruk.\n",
            "\n",
            "3.  **Kesimpulan Singkat**\n",
            "    Teks ini mengindikasikan adanya masalah teknis yang parah pada aplikasi, seperti sering *crash* dan tidak responsif, yang berujung pada pengalaman pengguna yang sangat negatif.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Prompt Debugging Example"
      ],
      "metadata": {
        "id": "X0mZiitYpEpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fix the prompt to make the output more specific."
      ],
      "metadata": {
        "id": "b1-XNkJJpISS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Tentukan sentimen teks berikut dalam SATU KATA saja:\n",
        "positive atau negative\n",
        "\n",
        "Teks: \"Fiturnya lengkap tapi sering error\"\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "UQs0Fe1UpF0o",
        "outputId": "9577c039-34b4-4902-c660-723ed1582858"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reusable Prompt Function"
      ],
      "metadata": {
        "id": "iZFVQJNkpRrx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt is made into a function (best practice engineering)."
      ],
      "metadata": {
        "id": "tnirmfdMpfT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_prompt(text):\n",
        "    prompt = f\"\"\"\n",
        "    Klasifikasikan sentimen teks berikut.\n",
        "    Jawab hanya dengan: positive atau negative.\n",
        "\n",
        "    Teks: \"{text}\"\n",
        "    \"\"\"\n",
        "    return model.generate_content(prompt).text.strip()"
      ],
      "metadata": {
        "id": "zb7kJdokpSwk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_prompt(\"Pelayanan sangat buruk\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "LNqYGw1QpX_c",
        "outputId": "e5a5eb17-f3d4-4fa2-c05d-77fcf545d5fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_prompt(\"Produk sesuai deskripsi\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "u7ZERBvEpahC",
        "outputId": "0b758c4b-0785-4a47-e1db-b0c66540e7b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we hands on some of basic in prompt engineering. Some conclusion that we can see\n",
        "\n",
        "- Prompt engineering is the primary way to control LLM without fine-tuning.\n",
        "- Prompt structure is more important than prompt length.\n",
        "- Prompts are engineering assets where it can be versioned and tested."
      ],
      "metadata": {
        "id": "ii5zpNuRpsk8"
      }
    }
  ]
}