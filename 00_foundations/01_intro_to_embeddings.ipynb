{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Embeddings\n",
    "\n",
    "In this notebook, we will explore the concept of **text embeddings**. Embeddings are numerical representations (vectors) of text that capture semantic meaning. They are the foundation of modern AI applications like Semantic Search, RAG (Retrieval Augmented Generation), and Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install sentence-transformers numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Embeddings\n",
    "\n",
    "We will use the `sentence-transformers` library, which provides easy access to state-of-the-art models for generating sentence embeddings. We'll use a small but efficient model called `all-MiniLM-L6-v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Our corpus of sentences\n",
    "sentences = [\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "    \"The new movie is awesome\",\n",
    "    \"The dog is in the garden\",\n",
    "    \"I love pasta and pizza\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "# Output should be (5, 384) because 'all-MiniLM-L6-v2' creates 384-dimensional vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Vectors\n",
    "\n",
    "Let's look at a single embedding. It is just a list of floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first embedding\n",
    "print(f\"First sentence: '{sentences[0]}'\")\n",
    "print(f\"First 10 dimensions of the vector: {embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Measuring Similarity (Cosine Similarity)\n",
    "\n",
    "To determine how similar two sentences are, we compare their vectors. The most common metric is **Cosine Similarity**, which measures the cosine of the angle between two vectors.\n",
    "\n",
    "Formula:\n",
    "$$ \\text{similarity} = \\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} $$\n",
    "\n",
    "where $A \\cdot B$ is the dot product and $\\|A\\|$ is the magnitude (norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "# Compare \"The cat sits outside\" with \"The dog is in the garden\"\n",
    "sim_cat_dog = cosine_similarity(embeddings[0], embeddings[3])\n",
    "print(f\"Similarity (Cat vs Dog): {sim_cat_dog:.4f}\")\n",
    "\n",
    "# Compare \"The cat sits outside\" with \"A man is playing guitar\"\n",
    "sim_cat_guitar = cosine_similarity(embeddings[0], embeddings[1])\n",
    "print(f\"Similarity (Cat vs Guitar): {sim_cat_guitar:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should observe that the similarity between the two animal-related sentences is higher than the similarity between the cat sentence and the guitar sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple Semantic Search\n",
    "\n",
    "Now let's implement a basic search. We will take a query, embed it, and find the closest sentence in our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"food\"\n",
    "query_embedding = model.encode([query])[0]\n",
    "\n",
    "# Calculate similarity with all sentences\n",
    "scores = []\n",
    "for i, sent_emb in enumerate(embeddings):\n",
    "    score = cosine_similarity(query_embedding, sent_emb)\n",
    "    scores.append((score, sentences[i]))\n",
    "\n",
    "# Sort by score descending\n",
    "scores.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"Top matches:\")\n",
    "for score, sentence in scores:\n",
    "    print(f\"{score:.4f} | {sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
